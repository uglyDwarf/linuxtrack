<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
  <title>Device setup</title>
  <meta name="generator" content="Bluefish 2.0.2" >
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>

The first step in Linuxtrack configuration is selection of the tracking device.
Select the device of your choice from the "<strong>Tracking device</strong>" combo box and the device 
specific options appear below.
<p> 
If you can't find the device you want to use (e.g. web-cam attached after Linuxtrack GUI was started, ...), 
press the "<strong>Refresh</strong>" button and check again.
<p>

Next thing that you can set is the camera orientation - normally you should not need to change this...<br>
However, if your tracking device is positioned in any other way than in front of you with top pointing up
(you mounted TrackIR upside down for some reason, or you use laptop with a web-cam chip mounted upside down,...),
change the </strong>Camera Orientation</strong> to match your device's orientation.
<p>
Supported device types are the following:
<p>
<A href="#Wiimote">Wiimote Setup</A><br>
<A href="#Web-cam">Web-cam Setup</A><br>
<A href="#Web-cam_ft">Web-cam Setup for face tracking</A><br>
<A href="#TIR">TrackIR Setup (including SmartNav devices)</A><br>
<A href="#JOY">HID device setup</A><br>


<h1><A name="Wiimote">Wiimote Setup</A></h1>
<img src="Wiimote.png" width="100%" >
<p>If Wiimote is the tracking device of your choice, first of all, make sure you have the Wiimote
server running (comes along with Linuxtrack) and connected to the Wiimote.
<p>
If Wiimote server is not running, then start it, press the <strong>Connect</strong> button and then 
simultaneously press buttons "1" and "2" on the Wiimote . After a short pause, you should see the 
state change to Connected and one of LEDs on your Wiimote should blink briefly about every 5 seconds.
<p>
Due to the nature of Wiimote there is no way to tweak any parameters except for which LEDs should indicate 
running/paused tracker. Just select which LEDs should be on in the Running state and which should be on in 
the Paused state. However, if the battery life is crucial for you, you should turn all LEDs off at least in the 
Running state (in this state you are going to spend most of the time after all).
<p>
<A href="#StartTracking">Now you can try to start the tracking to verify the device is set up correctly.</A>



<h1><A name="Web-cam">Web-cam Setup</A></h1>
<img src="Webcam.png" width="100%" >
<p>To configure a web-cam, first of all you have to set the <strong>Pixel Format</strong>.
The preferred format is YUYV (native UVC web-cam format), but you can experiment and see
which one works the best for you (just avoid the JPEG/MJPG formats as they aren't supported).
</p>
<p>Continue by selecting the desired <strong>Resolution &amp; Frame rate</strong>.
The safest bet would be something around 352x288@30; when tracking with these setting works, you can 
experiment with different resolutions and frame rates.
</p>
<p>
To ensure best frame rate (stable and high), it is recommended to turn at least the Automatic exposure off
(better turn off the rest of Auto... features too), if possible.
Then set the exposure manually and tweak the rest of parameters (brightness, contrast, ...) to get good picture.
On Linux you can use the guvcview for this purpose.

<p>
<A href="#StartTracking">Now you can try to start the tracking to verify the device is set up correctly.</A>



<h1><A name="Web-cam_ft">Web-cam Setup for face tracking</A></h1>
<img src="Facetracker.png" width="100%" >
<p>To configure a web-cam, first of all you have to set the <strong>Pixel Format</strong>.
The preferred format is YUYV (native UVC web-cam format), but you can experiment and see
which one works the best for you (just avoid the JPEG/MJPG formats as they aren't supported).
</p>
<p>Continue by selecting the desired <strong>Resolution &amp; Frame rate</strong>. <br>
The safest bet would be something around 352x288@30; when tracking with these setting works, you can 
experiment with different resolutions and frame rates.
</p>
<p>The last thing to set before the first test is the path to the cascade used to track the face.
OpenCV Haar and LBP cascades are supported.
If the default cascade doesn't suit you, just browse to the cascade of your choice. On Linux you can 
find them in the following paths:

<ul>
<li>Mac: just press <b>Open</b> button and choose
<li>Linux: <b>/opt/linuxtrack-X.X.X/share/OpenCV</b> (if you use universal package)</li>
<li>Linux: <b>/usr/share/doc/opencv</b> (your distro's package)</li>
<li>Linux: <b>/usr/share/doc/opencv-doc</b> (your distro's package)</li>
<li><b>http://alereimondo.no-ip.org/OpenCV/34</b></li>
</ul>
You should choose a frontal face detection cascade. If you are short on CPU power, try the LBP cascade 
<b>lbpcascade_frontalface.xml</b> - it consumes much less CPU, but the tracking is said to be a bit 
less reliable. Just try it out and see how does it work for you.
</p>
<A href="#StartTracking">Now you can try to start the tracking to verify the device is set up correctly.</A>



<h1><A name="TIR">TrackIR/SmartNav Setup</A></h1>
<img src="Trackir.png" width="100%" ><br>
If you are a Mac user, you can skip to the next paragraph now...
When you intend to use TrackIR on Linux, most probably you'll need to get access rights to the device.
The easiest way to do that, is to install the 99-TIR.rules file (comes with Linuxtrack) to the udev rules 
directory (on Ubuntu it is /lib/udev/rules, but other distros might differ a bit in this respect). 
When the rule is there, just re-plug the TrackIR and you should be able to access it.
<p>
If you have never used TrackIR before, you are going to need to install the firmware. Just press the 
<b>Install Firmware</b> button and follow the instructions. 
Usually just pressing <b>Download</b> button on the presented dialog is all that is needed - it downloads the
driver package from NP and extracts firmware needed to run the device.
<p>
<A href="#StartTracking">Now you can try to start the tracking to verify the device is set up correctly.</A>


<h1><A name="JOY">HID device setup</h1>
Linuxtrack allows you to use a HID device (joystick, ED tracker, ...) as a source of headtracking information
(at the moment Linux only).<br>

Select the device you intend to use in the <b>Tracking Device</b> combobox. You'll probably be presented with
a warning message that you need to use the Absolute model; in that case head to the <b>Model Setup</b> pane,
select the Absolute model in the <b>Model Name</b> combobox and head back to the <b>Device Setup</b> pane.<br>

You can also select an interface to use for communication with the device. Of the two possibilities (Evdev/Joystick),
probably the Evdev is a beeter choice, where possible. The reason is, that evdev provides raw data from the device,
which can be used directly; the joystick interface is dependent on the proper calibration using the jscal command
(or some GUI equivalent) - without it the device might be off center and not using the full range of available motion.
<br>

Now you can select the device axes to use for each of available six head rotations/movements. The easiest way
is to start the tracking by pressing the <b>Start</b> button in the Tracking window and switch to the <b>3D View</b>.
Go back to the <b>Device Setup</b> and in the <b>Pitch</b> combo select one of the available axes; now wiggle all the
device axes and see which one will control the pitch in the <b>3D View</b>. If the active axis was intended for
different rotation/movement, then select it as a source for the appropriate rotation/movement. If the axis works 
"backwards", go to the <b>Tracking Setup</b> pane and check the <b>Invert</b> checkbox for the rotation/movment in
question. In the <b>3D View</b> confirm that the axis work as expected and move to the next one.
<p>
When done with axes setup, you can jump to the <A href="axes_setup.htm">Tracking Setup</A> chapter.


<h1><A name="#StartTracking">Starting the tracking for the first time</A></h1>
<img src="CamPreview.png" width="100%" ><br>
To start the tracking, switch to the <strong>Tracking window</strong>. 
There you can start, pause and stop the tracking and there is a button to recenter the tracker
(needed when your view is off while looking to the center of the screen).
It also contains the frame counter and FPS indication towards the bottom left corner of the window.
<p>
There are two panes in this window, the first pane being the <strong>Camera View</strong>.
This pane allows you to troubleshoot the tracking - it shows exactly what the camera sees,
so it can show you for example any interfering light sources, unwanted reflections and so on.
The second pane, <strong>3D view</strong> shows what the result is going to look like in the simulator.
<p>
To start the tracking, all you have to do is press the <strong>Start</strong> button and wait for the
device to initialize (usually takes couple of seconds).
<p>
In case of head tracking, you should see your head in the <strong>Camera View</strong> pane, with a 
white rectangle around it, or in case of model based tracking there should be 3 
(or 1 in case of single point model) "blobs" (fields of bright pixels), each of which 
has a white cross inside (means a valid blob). You should check, that the rectangles/blobs with crosses are
there through the full range of motions you plan to use.


<h1><A name="#Troubleshooting">Troubleshooting the tracking</A></h1>
When there are any problems with tracking, always look at the <strong>Camera View</strong> first, to check
if there aren't any interferences or other visible problems.

<p>Some devices allow you to do some "post-processing" steps
to discriminate some of the interferences, but the first rule of troubleshooting is this: the best way to get 
rid of the interference is to remove it physically.
<p>
<ul>
<li>A light bulb in the field of view of your camera - the best way is to move the camera in
such a way, that the bulb gets out of the camera's field of view. 
<p>
With infrared sensitive devices (TrackIR/SmartNav, Wiimote, ...) the interference sources might not be all that easily identifiable - things like light bulbs, lit cigars, candles, IR TV and other remote controls can cause considerable interference. Also sun can cause significant problems - not only direct sun, but also areas lit (and heated) by sun can be sources of severe interference.
<li>When using reflective markers (like TrackClip, primarily with TrackIR/SmartNav), there can be reflections from ones glasses or other reflective areas - there the solution might be to use a TrackClip Pro, or similar active "model", as it allows to turn off TrackIR's infra red LEDs.
<li>Face tracking can be fooled easily by visually nonuniform background - having a plain color wall behind you
is the best way to ensure smooth tracking.
</ul>
<p>
When such a solution is not possible, different devices have different means that might help you to achieve 
better tracking results.
<h2>Wiimote</h2>
Unfortunately Wiimote doesn't allow any tweaking, as the whole image processing is done in the device
itself. So the only way to deal with problems is to use the advice above and physically remove the interfering 
objects from sensor's field of view.

<h2>Web-cam and TrackIR</h2>
Both web-cam and TrackIR share similar means of getting rid of sources of interference. The first of them
is the threshold setup - when there are for example some unwanted reflections in camera's field of view,
try to set the threshold somewhat higher; if the unwanted blobs disappeared, then check that the correct blobs
have the white crosses inside them through the whole range of motion you intend to use. If the wanted blob 
or the cross inside it disappears, you need to set the threshold somewhat lower.
<p>
Another way to discriminate the "bad" blobs is according to their size - set the 
<strong>Valid blob size</strong> to values, that only the valid blobs satisfy (for higher resolution devices the range of values might be in range of 200 - 600). Just note, that these unwanted
blobs can still interfere with the tracking, especially when they merge with some valid blob. Also don't forget
to check, the whole range of motion you intend to use - for example setting the lower limit too high might break tracking when you move your head farther away from the camera.
<p>
Specialty of some TrackIR models, when using the reflective model is setting of the illuminating IR LEDs 
brightness. This can help you weaken unwanted reflections - just set the <strong>IR LEDs brightness</strong> somewhat lower.
<p>
When using a web-cam, make sure it is correctly focused and you get sharp image (best checked in some external
application).
<p>
To minimize the impact of the background light on the web-cam, you might need a visible light filter - piece of 
magnetic tape material, exposed film, piece of magnetic material from diskette or even piece of black 
stocking might help there. 

<p>Some web-cams also contain IR filters, that can completely filter out light from IR LEDs. However removal 
of the IR filter might be non-trivial and you risk irreparable damage to the camera, so try that only as a 
last resort (for example you might use ordinary visible light LEDs instead; also higher current might help 
to "burn through" the IR filter, but be careful not to burn the LEDs instead!).
<p>
<h2>Web-cam face tracker</h2>
When face tracking is jumpy, first of all, make sure that the face is being recognized correctly and the 
recognition is stable.
For example, when the background is not plain, there might be a pattern there that is being recognized
as a face by the tracker. If that is the case, all you can do is to obscure the offending thing/pattern.
The best results are achieved with plain single color background, where your face has a good contrast.
<p>
Also make sure that your face is well lit, but without sharp shadows.
<p>
If the rectangle stays around your face, but the tracking is still jumpy, you should adjust the 
<stong>Smoothing</strong> slider - moving the slider right steadies the tracking.
Try adjusting the <b>Filter Factor</b> on the <b>Tracking setup</b> tab too - these two filters
have somewhat different characteristics and complement each other. 
<p>
The smoothing filter actually averages input values, ironing out big jumps, but it also introduces a lag. 
The filter in the <b>Tracking setup</b> tab works best when smoothing small jitter. 
Try finding some sweet spot that works for you.
<p>
To optimize the CPU usage, you may try to move the <strong>Optimize for</strong> slider towards the 
<strong>Speed</strong> end, trading a bit of precision for a considerably lower CPU usage.
</body>
</html>
